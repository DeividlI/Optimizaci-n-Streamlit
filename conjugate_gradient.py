import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

def busqueda_seccion_dorada(f, a, b, tol=1e-7, max_iter=100):
    """Tu implementaciÃ³n de la bÃºsqueda de secciÃ³n dorada para la bÃºsqueda lineal."""
    phi = (1 + np.sqrt(5)) / 2
    resphi = 2 - phi
    c = a + resphi * (b - a)
    d = b - resphi * (b - a)
    fc = f(c)
    fd = f(d)
    for _ in range(max_iter):
        if abs(d - c) < tol:
            return (c + d) / 2
        if fc < fd:
            b, d, fd, c, fc = d, c, fc, a + resphi * (b - a), f(a + resphi * (b - a))
        else:
            a, c, fc, d, fd = c, d, fd, b - resphi * (b - a), f(b - resphi * (b - a))
    return (a + b) / 2

def conjugate_gradient_algorithm(f, grad_f, x0, tol1, tol2, max_iter):
    k = 0
    x = np.array(x0, dtype=float)
    g = grad_f(x)
    d = -g
    epsilon = 1e-12
    path = [x.copy()]
    table_data = []

    while np.linalg.norm(g) > tol1 and k < max_iter:
        line_search_func = lambda alpha: f(x + alpha * d)
        alpha_k = busqueda_seccion_dorada(line_search_func, a=0.0, b=1.0, tol=tol2)
        
        x_new = x + alpha_k * d
        path.append(x_new.copy())
        
        table_data.append({
            'IteraciÃ³n (k)': k,
            'xk': f"[{x[0]:.4f}, {x[1]:.4f}]",
            'f(xk)': f(x),
            '||âˆ‡f(xk)||': np.linalg.norm(g),
            'alpha*': alpha_k,
        })
        
        if np.linalg.norm(x_new - x) / (np.linalg.norm(x) + epsilon) < tol2:
            x = x_new
            break
            
        g_new = grad_f(x_new)
        beta_k_plus_1 = np.dot(g_new, g_new) / (np.dot(g, g) + epsilon)
        d = -g_new + beta_k_plus_1 * d
        g, x, k = g_new, x_new, k + 1
        
    return x, f(x), k, np.array(path), table_data

def plot_cg_results(ax, f, path, intervals):
    x_min, x_max = intervals[0]; y_min, y_max = intervals[1]
    x_grid = np.linspace(x_min, x_max, 200)
    y_grid = np.linspace(y_min, y_max, 200)
    X, Y = np.meshgrid(x_grid, y_grid)
    Z = np.array([f(p) for p in np.stack([X.ravel(), Y.ravel()], axis=-1)]).reshape(X.shape)

    min_z, max_z = np.min(Z), np.max(Z)
    levels = np.logspace(np.log10(min_z if min_z > 0 else 1e-3), np.log10(max_z if max_z > 0 else 1), 20)
    
    ax.contourf(X, Y, Z, levels=levels, cmap='viridis_r', alpha=0.85)
    ax.plot(path[:, 0], path[:, 1], 'r-o', markersize=4, linewidth=2, label='Trayectoria')
    ax.scatter(path[0, 0], path[0, 1], c='cyan', marker='P', s=200, zorder=3, label='Inicio')
    ax.scatter(path[-1, 0], path[-1, 1], c='lime', marker='*', s=250, zorder=3, label='MÃ­nimo')
    
    ax.set_title("OptimizaciÃ³n con Gradiente Conjugado", fontsize=16)
    ax.set_xlabel('xâ‚€'); ax.set_ylabel('xâ‚')
    ax.legend(); ax.grid(True, linestyle='--', alpha=0.6)
    ax.set_xlim(x_min, x_max); ax.set_ylim(y_min, y_max)

def show_conjugate_gradient(FUNCIONES):
    st.markdown("## ğŸ“ Gradiente Conjugado")
    st.markdown("""
    El mÃ©todo del Gradiente Conjugado (FÃ³rmula de Fletcher-Reeves) es una mejora sofisticada sobre el descenso de gradiente. En lugar de moverse siempre en la direcciÃ³n del gradiente local, construye una secuencia de direcciones de bÃºsqueda que son "conjugadas".
    
    Esto le permite "recordar" las direcciones anteriores para no deshacer el progreso ya hecho, evitando el comportamiento en zigzag del mÃ©todo de Cauchy y convergiendo mucho mÃ¡s rÃ¡pido, especialmente en valles largos y estrechos.
    
    La direcciÃ³n de bÃºsqueda `d` se actualiza con un factor `Î²` que incorpora informaciÃ³n del gradiente anterior: `d_k = -âˆ‡f(x_k) + Î²_k * d_{k-1}`.
    """)

    with st.expander("ConfiguraciÃ³n del Algoritmo y la FunciÃ³n", expanded=True):
        col1, col2 = st.columns(2)
        with col1:
            funcion_seleccionada = st.selectbox("ğŸ¯ Selecciona la funciÃ³n:", list(FUNCIONES.keys()), key="cg_func")
            info_funcion = FUNCIONES[funcion_seleccionada]
            
            st.markdown("**ParÃ¡metros de Parada (Tolerancias):**")
            tol1 = st.number_input("Îµâ‚ (Tolerancia de ||âˆ‡f||)", 0.0, 1.0, 1e-6, format="%.7f")
            tol2 = st.number_input("Îµâ‚‚ (Tolerancia de paso)", 0.0, 1.0, 1e-6, format="%.7f")

        with col2:
            st.latex(info_funcion.get("latex", ""))
            st.markdown("**ParÃ¡metros de EjecuciÃ³n:**")
            max_iter = st.slider("M (MÃ¡ximo de iteraciones)", 10, 2000, 1000, 20)
            
            st.markdown("**ğŸ“ Punto Inicial (xâ‚€):**")
            intervalos = info_funcion["intervalos"]
            x0_vals = [st.number_input(f'x0_{i}', value=np.random.uniform(inter[0], inter[1]), key=f'cg_x0_{i}') for i, inter in enumerate(intervalos)]
            x0 = np.array(x0_vals)

    if st.button("ğŸš€ Ejecutar Gradiente Conjugado", key="run_cg"):
        f = info_funcion["funcion"]
        grad_f = info_funcion.get("gradiente")
        
        if not grad_f:
            st.error(f"Error: La funciÃ³n '{funcion_seleccionada}' no tiene un gradiente analÃ­tico definido en el diccionario. Este mÃ©todo lo requiere.")
            return

        with st.spinner("Optimizando con el mÃ©todo del Gradiente Conjugado..."):
            min_x, min_f, iteraciones, path, table_data = conjugate_gradient_algorithm(
                f, grad_f, x0, tol1, tol2, max_iter
            )
        
        st.success("âœ… OptimizaciÃ³n completada!")
        
        col1, col2, col3 = st.columns(3)
        col1.metric("ğŸ¯ SoluciÃ³n Encontrada (x*)", f"[{min_x[0]:.5f}, {min_x[1]:.5f}]")
        col2.metric("ğŸ“Š Valor Ã“ptimo f(x*)", f"{min_f:.6f}")
        col3.metric("ğŸ”„ Iteraciones", f"{iteraciones}")

        st.markdown("### ğŸ“ˆ VisualizaciÃ³n de la OptimizaciÃ³n")
        fig, ax = plt.subplots(figsize=(10, 8))
        plot_cg_results(ax, f, path, info_funcion["intervalos"])
        st.pyplot(fig)
        
        st.markdown("### ğŸ“‹ Tabla de Iteraciones")
        st.dataframe(pd.DataFrame(table_data), use_container_width=True)

        # ğŸ”¹ InformaciÃ³n adicional basada en las diapositivas
        st.markdown("### ğŸ“˜ InformaciÃ³n adicional: MÃ©todo del Gradiente Conjugado")
        st.markdown("""
        El **MÃ©todo del Gradiente Conjugado** pertenece a la categorÃ­a de mÃ©todos **basados en gradiente** para optimizaciÃ³n numÃ©rica. A diferencia del descenso de gradiente simple, este mÃ©todo utiliza direcciones de bÃºsqueda conjugadas para evitar oscilaciones y acelerar la convergencia.

        ğŸ” **CaracterÃ­sticas clave:**
        - DiseÃ±ado principalmente para minimizar funciones **cuadrÃ¡ticas** o suavemente curvadas.
        - Se basa en la fÃ³rmula: $\\vec{d}_k = -\\nabla f(x_k) + \\beta_k \\vec{d}_{k-1}$ con $\\beta_k$ de Fletcher-Reeves.
        - Utiliza **bÃºsqueda unidireccional** (como secciÃ³n dorada) para determinar $\\alpha_k$.

        ğŸ§  **Fundamento teÃ³rico:**
        - Forma parte de los **mÃ©todos numÃ©ricos iterativos**.
        - Mejora los mÃ©todos de descenso simple, evitando zigzags en valles estrechos.
        - Muy eficiente en problemas con muchas variables donde calcular la Hessiana serÃ­a costoso.

        ğŸ“ **Ventajas y desventajas:**
        - âœ… No requiere almacenar ni invertir matrices grandes.
        - âœ… Converge mÃ¡s rÃ¡pido que el gradiente simple en muchos casos.
        - âŒ Puede perder eficiencia si la funciÃ³n no es bien condicionada.
        - âŒ Requiere gradiente exacto o muy bien estimado.

        ğŸ“š Basado en las diapositivas de â€œOptimizaciÃ³n - clase introductoriaâ€ (AdÃ¡n E. Aguilar) y el libro de Kalyanmoy Deb.
        """)
